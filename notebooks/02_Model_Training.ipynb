{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "b51c4e93",
            "metadata": {},
            "source": [
                "# Model Training: ALS, SVD, and Content-Based\n",
                "\n",
                "In this notebook, we will train three recommender system components:\n",
                "1.  **ALS (Alternating Least Squares)** from the `implicit` library: For candidate generation (collaborative filtering).\n",
                "2.  **SVD (Singular Value Decomposition)** from `scikit-surprise`: For scoring and ranking.\n",
                "3.  **Content-Based (TF-IDF)**: Using movie genres to find similar items, useful for cold-start or hybrid approaches.\n",
                "\n",
                "We will save all trained models and artifacts to the `models/` directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "52f1a213",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import scipy.sparse as sparse\n",
                "import implicit\n",
                "from surprise import Dataset, Reader, SVD\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "import pickle\n",
                "import os\n",
                "\n",
                "# Ensure models directory exists\n",
                "os.makedirs(\"../models\", exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e9a17e9",
            "metadata": {},
            "source": [
                "## 1. Load Data (Ratings)\n",
                "We load only the necessary columns: UserID, MovieID, Rating. **Timestamp is ignored**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "28e39860",
            "metadata": {},
            "outputs": [],
            "source": [
                "RATINGS_FILE = \"../data/ml-1m/ratings.dat\"\n",
                "ratings_cols = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
                "\n",
                "# Load and drop timestamp\n",
                "ratings = pd.read_csv(RATINGS_FILE, sep='::', header=None, names=ratings_cols, engine='python', encoding='latin-1')\n",
                "ratings = ratings.drop(columns=['Timestamp'])\n",
                "\n",
                "print(f\"Ratings shape: {ratings.shape}\")\n",
                "ratings.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "051348d8",
            "metadata": {},
            "source": [
                "## 2. Train ALS Model (Implicit)\n",
                "\n",
                "ALS requires a sparse matrix (User x Item or Item x User). We'll treat ratings as \"confidence\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bf3de51e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create categorical types for mapping IDs to matrix indices efficiently\n",
                "users = ratings['UserID'].astype(\"category\")\n",
                "movies_cat = ratings['MovieID'].astype(\"category\") # Rename to avoid clash with movies df later\n",
                "\n",
                "# Create sparse matrix (rows=items, cols=users for implicit training)\n",
                "item_user_matrix = sparse.csr_matrix(\n",
                "    (ratings['Rating'].astype(float), (movies_cat.cat.codes, users.cat.codes))\n",
                ")\n",
                "\n",
                "# Also create user_item matrix for inference references\n",
                "user_item_matrix = sparse.csr_matrix(\n",
                "    (ratings['Rating'].astype(float), (users.cat.codes, movies_cat.cat.codes))\n",
                ")\n",
                "\n",
                "print(f\"Matrix Sparsity: {100 * (1 - item_user_matrix.nnz / (item_user_matrix.shape[0] * item_user_matrix.shape[1])):.2f}%\")\n",
                "\n",
                "# Initialize ALS model\n",
                "als_model = implicit.als.AlternatingLeastSquares(\n",
                "    factors=50, \n",
                "    regularization=0.1, \n",
                "    iterations=20, \n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# Train\n",
                "print(\"Training ALS model...\")\n",
                "als_model.fit(item_user_matrix)\n",
                "print(\"ALS Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2b26419a",
            "metadata": {},
            "source": [
                "### Save ALS Artifacts\n",
                "We need to save the model, but ALSO the mappings from Real IDs to Matrix Indices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "63d5d9bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mappings\n",
                "user_map = dict(enumerate(users.cat.categories))\n",
                "movie_map = dict(enumerate(movies_cat.cat.categories))\n",
                "user_inv_map = {v: k for k, v in user_map.items()}\n",
                "movie_inv_map = {v: k for k, v in movie_map.items()}\n",
                "\n",
                "# Save everything in a dictionary\n",
                "als_artifacts = {\n",
                "    \"model\": als_model,\n",
                "    \"user_item_matrix\": user_item_matrix,\n",
                "    \"user_inv_map\": user_inv_map,  # Real UserID -> Matrix Index\n",
                "    \"movie_inv_map\": movie_inv_map, # Real MovieID -> Matrix Index\n",
                "    \"user_map\": user_map,          # Matrix Index -> Real UserID\n",
                "    \"movie_map\": movie_map         # Matrix Index -> Real MovieID\n",
                "}\n",
                "\n",
                "with open(\"../models/als_artifacts.pkl\", \"wb\") as f:\n",
                "    pickle.dump(als_artifacts, f)\n",
                "    \n",
                "print(\"ALS artifacts saved to ../models/als_artifacts.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a3c7a1e3",
            "metadata": {},
            "source": [
                "## 3. Train Content-Based Model (TF-IDF on Genres)\n",
                "As per `tech_note_fe_genres.MD`, we will use TF-IDF to represent movie genres. This allows us to find similar movies based on content."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f4d52cfa",
            "metadata": {},
            "outputs": [],
            "source": [
                "MOVIES_FILE = \"../data/ml-1m/movies.dat\"\n",
                "movies_cols = ['MovieID', 'Title', 'Genres']\n",
                "\n",
                "print(\"Loading movies for Content-Based Filtering...\")\n",
                "movies = pd.read_csv(MOVIES_FILE, sep='::', header=None, names=movies_cols, engine='python', encoding='latin-1')\n",
                "\n",
                "# Preprocess Genres: Replace pipe with space\n",
                "movies['genres_str'] = movies['Genres'].str.replace('|', ' ', regex=False)\n",
                "\n",
                "# TF-IDF Vectorization\n",
                "# Token pattern to capture hyphenated genres like Sci-Fi\n",
                "tfidf = TfidfVectorizer(token_pattern=r\"(?u)\\b[A-Za-z-]+\\b\")\n",
                "tfidf_matrix = tfidf.fit_transform(movies['genres_str'])\n",
                "\n",
                "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
                "print(f\"Vocabulary: {list(tfidf.vocabulary_.keys())[:10]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5d6c038",
            "metadata": {},
            "source": [
                "### Save Content-Based Artifacts\n",
                "We save the matrix, the vectorizer, and the movies DataFrame (for metadata mapping)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b9609bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "content_artifacts = {\n",
                "    \"tfidf_matrix\": tfidf_matrix,\n",
                "    \"tfidf_vectorizer\": tfidf,\n",
                "    \"movies_df\": movies[['MovieID', 'Title', 'Genres']] # Keep metadata\n",
                "}\n",
                "\n",
                "with open(\"../models/content_artifacts.pkl\", \"wb\") as f:\n",
                "    pickle.dump(content_artifacts, f)\n",
                "\n",
                "print(\"Content-based artifacts saved to ../models/content_artifacts.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "de9ecc12",
            "metadata": {},
            "source": [
                "## 4. Train SVD Model (Surprise)\n",
                "Surprise is designed for explicit feedback (ratings prediction)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Reader (MovieLens is 1-5 scale)\n",
                "reader = Reader(rating_scale=(1, 5))\n",
                "\n",
                "# Load data from DataFrame\n",
                "data = Dataset.load_from_df(ratings[['UserID', 'MovieID', 'Rating']], reader)\n",
                "\n",
                "# Build full trainset\n",
                "trainset = data.build_full_trainset()\n",
                "\n",
                "# Initialize SVD\n",
                "svd_model = SVD(n_factors=100, n_epochs=20, random_state=42)\n",
                "\n",
                "# Train\n",
                "print(\"Training SVD model...\")\n",
                "svd_model.fit(trainset)\n",
                "print(\"SVD Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Save SVD Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(\"../models/svd_model.pkl\", \"wb\") as f:\n",
                "    pickle.dump(svd_model, f)\n",
                "    \n",
                "print(\"SVD model saved to ../models/svd_model.pkl\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
